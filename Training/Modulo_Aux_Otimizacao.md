# M√≥dulo Auxiliar: Otimiza√ß√£o de Queries no Greenplum 7

**Dura√ß√£o:** 60 minutos  
**Objetivo:** Aprender a analisar, diagnosticar e otimizar queries lentas no Greenplum 7.

---

## üìö √çndice
1. [Fundamentos do EXPLAIN](#1-fundamentos-do-explain)
2. [Identificando Gargalos](#2-identificando-gargalos)
3. [Otimiza√ß√µes Comuns](#3-otimiza√ß√µes-comuns)
4. [Configura√ß√µes do Greenplum](#4-configura√ß√µes-do-greenplum)
5. [Troubleshooting](#5-troubleshooting)

---

## 1. Fundamentos do EXPLAIN

### O que √© EXPLAIN?

**EXPLAIN** mostra o **plano de execu√ß√£o** que o otimizador do Greenplum escolheu para sua query.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SUA QUERY                                       ‚îÇ
‚îÇ SELECT * FROM vendas WHERE data >= '2024-01-01'‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    OTIMIZADOR (ORCA ou Planner)
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PLANO DE EXECU√á√ÉO                               ‚îÇ
‚îÇ 1. Scan tabela vendas (apenas parti√ß√µes 2024)  ‚îÇ
‚îÇ 2. Filter data >= '2024-01-01'                  ‚îÇ
‚îÇ 3. Gather dados dos segmentos                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Varia√ß√µes do EXPLAIN

```sql
-- 1. EXPLAIN simples (sem executar)
EXPLAIN
SELECT * FROM vendas WHERE data_venda >= '2024-01-01';
```

**üí° Mostra:** Plano **estimado**, n√£o executa query

```sql
-- 2. EXPLAIN ANALYZE (executa e mostra tempo real)
EXPLAIN ANALYZE
SELECT * FROM vendas WHERE data_venda >= '2024-01-01';
```

**üí° Mostra:** Plano **real** + tempos de execu√ß√£o + linhas reais

```sql
-- 3. EXPLAIN com op√ß√µes detalhadas
EXPLAIN (ANALYZE true, VERBOSE true, BUFFERS true, COSTS true)
SELECT * FROM vendas WHERE data_venda >= '2024-01-01';
```

**üí° Mostra:** M√°ximo de detalhes (colunas, I/O, custos)

---

### Exerc√≠cio 1.1: Lendo um EXPLAIN B√°sico

**Passo 1:** Criar tabela de exemplo

```sql
-- Tabela de vendas (n√£o particionada, para exemplo)
CREATE TABLE vendas_exemplo (
    venda_id BIGSERIAL,
    data_venda DATE,
    cliente_id INTEGER,
    produto_id INTEGER,
    valor NUMERIC(10,2)
)
DISTRIBUTED BY (venda_id);
```

```sql
-- Inserir dados
INSERT INTO vendas_exemplo (data_venda, cliente_id, produto_id, valor)
SELECT 
    CURRENT_DATE - (random() * 365)::INTEGER,
    (random() * 10000)::INTEGER,
    (random() * 500)::INTEGER,
    (random() * 5000)::NUMERIC(10,2)
FROM generate_series(1, 100000);
```

```sql
-- ANALYZE para estat√≠sticas
ANALYZE vendas_exemplo;
```

**Passo 2:** EXPLAIN simples

```sql
EXPLAIN
SELECT COUNT(*), SUM(valor)
FROM vendas_exemplo
WHERE data_venda >= '2024-01-01';
```

**üìä Resultado t√≠pico:**

```
Finalize Aggregate  (cost=0.00..431.00 rows=1 width=40)
  ->  Gather Motion 2:1  (slice1; segments: 2)  (cost=0.00..431.00 rows=1 width=40)
        ->  Partial Aggregate  (cost=0.00..431.00 rows=1 width=40)
              ->  Seq Scan on vendas_exemplo  (cost=0.00..431.00 rows=25000 width=14)
                    Filter: (data_venda >= '2024-01-01'::date)
```

**üîç Leitura (de baixo para cima):**

1. **Seq Scan:** Varredura sequencial da tabela
   - `Filter: (data_venda >= '2024-01-01')`: Filtro aplicado
   - `rows=25000`: Estimativa de linhas que passam filtro
   - `cost=0.00..431.00`: Custo estimado (in√≠cio..fim)

2. **Partial Aggregate:** Agrega√ß√£o local em cada segmento
   - `SUM(valor), COUNT(*)` calculados localmente

3. **Gather Motion 2:1:** Coleta dados de 2 segmentos para 1 (master)
   - `slice1; segments: 2`: Executa em paralelo em 2 segmentos

4. **Finalize Aggregate:** Agrega√ß√£o final no master
   - Soma resultados parciais dos segmentos

**Passo 3:** EXPLAIN ANALYZE (executa query)

```sql
EXPLAIN ANALYZE
SELECT COUNT(*), SUM(valor)
FROM vendas_exemplo
WHERE data_venda >= '2024-01-01';
```

**üìä Resultado t√≠pico:**

```
Finalize Aggregate  (cost=0.00..431.00 rows=1 width=40) 
                    (actual time=89.123..89.125 rows=1 loops=1)
  ->  Gather Motion 2:1  (slice1; segments: 2)  (cost=0.00..431.00 rows=1 width=40)
                         (actual time=85.456..89.078 rows=2 loops=1)
        ->  Partial Aggregate  (cost=0.00..431.00 rows=1 width=40)
                               (actual time=82.345..82.347 rows=1 loops=1)
              ->  Seq Scan on vendas_exemplo  (cost=0.00..431.00 rows=25000 width=14)
                                              (actual time=1.234..75.678 rows=27345 loops=1)
                    Filter: (data_venda >= '2024-01-01'::date)
                    Rows Removed by Filter: 72655
Planning Time: 2.345 ms
Execution Time: 89.567 ms
```

**üîç Novos dados (ANALYZE):**

- `actual time=1.234..75.678`: Tempo **real** (in√≠cio..fim em ms)
- `rows=27345`: Linhas **reais** retornadas (vs estimado 25000)
- `loops=1`: Quantas vezes o n√≥ foi executado
- `Rows Removed by Filter: 72655`: Linhas descartadas pelo filtro
- `Planning Time: 2.345 ms`: Tempo para planejar query
- `Execution Time: 89.567 ms`: Tempo **total** de execu√ß√£o

**üí° An√°lise:**
- Estimativa (25k) vs Real (27k): **Pr√≥ximas** ‚Üí Estat√≠sticas OK
- 72% das linhas removidas por filtro ‚Üí Query n√£o muito seletiva

---

### Exerc√≠cio 1.2: Componentes do Plano GP7

**Slices (Fatias de Execu√ß√£o Paralela)**

```
Gather Motion 2:1  (slice1; segments: 2)
                    ^^^^^^
                    Slice 1 = Executa em 2 segmentos em paralelo
                    Slice 0 = Master (ap√≥s Gather)
```

**Motion Nodes (Movimenta√ß√£o de Dados)**

```sql
EXPLAIN ANALYZE
SELECT c.estado, COUNT(*), SUM(v.valor)
FROM vendas_exemplo v
JOIN clientes c ON v.cliente_id = c.cliente_id
GROUP BY c.estado;
```

**üìä Resultado mostrar√°:**

```
-> Redistribute Motion 2:2  (slice2)  ‚Üê Redistribui dados entre segmentos
     Hash Key: c.estado

-> Broadcast Motion 1:2  (slice3)  ‚Üê Copia tabela para todos segmentos
     
-> Gather Motion 2:1  (slice1)  ‚Üê Coleta resultados finais
```

**Tipos de Motion:**

| Motion | Padr√£o | Quando Ocorre | Custo |
|--------|--------|---------------|-------|
| **Gather Motion N:1** | N segmentos ‚Üí Master | Resultado final | Baixo (s√≥ resultado final) |
| **Redistribute Motion N:N** | Redistribui por hash | JOIN/GROUP BY sem co-location | **Alto** (move muitos dados) |
| **Broadcast Motion 1:N** | Copia para todos | Dimens√£o pequena em JOIN | M√©dio (se tabela pequena) |

**Partition Selector (Pruning)**

```sql
-- Tabela particionada
CREATE TABLE vendas_part (...) PARTITION BY RANGE (data_venda) ...;

EXPLAIN ANALYZE
SELECT * FROM vendas_part WHERE data_venda = '2024-06-15';
```

**üìä Resultado:**

```
-> Dynamic Seq Scan on vendas_part
     Partition Selector: $0
     Partitions selected: 1 (out of 12)  ‚Üê ‚úÖ Partition Pruning!
     Filter: (data_venda = '2024-06-15'::date)
```

**üí° Ideal:** `Partitions selected` deve ser **m√≠nimo** poss√≠vel!

---

## 2. Identificando Gargalos

### 2.1: Tempo Total vs Distribu√≠do

**An√°lise de onde o tempo est√° sendo gasto:**

```sql
EXPLAIN ANALYZE
SELECT cliente_id, SUM(valor)
FROM vendas_exemplo
GROUP BY cliente_id
ORDER BY SUM(valor) DESC
LIMIT 100;
```

**üìä Resultado:**

```
Limit  (actual time=245.123..245.234 rows=100 loops=1)
  ->  Gather Motion 2:1  (actual time=240.456..245.189 rows=100 loops=1)
        Merge Key: (sum(valor))
        ->  Limit  (actual time=235.789..235.890 rows=50 loops=1)
              ->  Sort  (actual time=230.123..232.456 rows=5000 loops=1)
                    Sort Method: top-N heapsort  Memory: 512kB
                    ->  HashAggregate  (actual time=180.234..185.567 rows=5000 loops=1)
                          Group Key: cliente_id
                          ->  Seq Scan  (actual time=1.234..145.678 rows=50000 loops=1)

Execution Time: 245.678 ms
```

**üîç An√°lise:**

| Opera√ß√£o | Tempo | % do Total | Gargalo? |
|----------|-------|------------|----------|
| Seq Scan | 145ms | 59% | ‚ö†Ô∏è Maior custo |
| HashAggregate | 5ms | 2% | ‚úÖ OK |
| Sort | 50ms | 20% | ‚ö†Ô∏è Moderado |
| Gather Motion | 5ms | 2% | ‚úÖ OK |
| **TOTAL** | **245ms** | 100% | |

**üí° Conclus√£o:** Seq Scan √© o gargalo (59% do tempo)

**A√ß√µes poss√≠veis:**
1. Particionar por data (se queries filtram por data)
2. Adicionar filtro WHERE para reduzir Seq Scan
3. Verificar se ANALYZE est√° atualizado

---

### 2.2: Rows Estimado vs Real

**Discrep√¢ncia entre estimativa e realidade indica problemas:**

```sql
EXPLAIN ANALYZE
SELECT * FROM vendas_exemplo v
JOIN produtos p ON v.produto_id = p.produto_id
WHERE v.data_venda >= '2024-01-01';
```

**üìä Cen√°rio problem√°tico:**

```
Hash Join  (cost=... rows=1000 width=...)  ‚Üê Estimado: 1000
           (actual time=... rows=500000 loops=1)  ‚Üê Real: 500k!
```

**üö® Problema:** Estimativa **500x menor** que realidade!

**Consequ√™ncias:**
- Otimizador escolhe plano errado (Nested Loop em vez de Hash Join)
- Aloca mem√≥ria insuficiente (spill to disk)
- Performance degradada

**Solu√ß√£o:**

```sql
-- 1. ANALYZE atualizado?
ANALYZE vendas_exemplo;
ANALYZE produtos;

-- 2. Testar novamente
EXPLAIN ANALYZE SELECT ...;

-- 3. Se persistir, aumentar statistics target
ALTER TABLE vendas_exemplo ALTER COLUMN data_venda SET STATISTICS 1000;
ANALYZE vendas_exemplo;
```

---

### 2.3: Spill to Disk (Work Memory Insuficiente)

**Opera√ß√£o precisa escrever tempor√°rio em disco (lento!):**

```sql
EXPLAIN ANALYZE
SELECT cliente_id, COUNT(*), SUM(valor)
FROM vendas_exemplo
GROUP BY cliente_id;
```

**üìä Problema (spill to disk):**

```
HashAggregate  (actual time=5678.123..5890.456 rows=10000 loops=1)
  Group Key: cliente_id
  Batches: 5  ‚Üê üö® M√∫ltiplos batches = spill to disk!
  Memory Usage: 4096kB
  Disk Usage: 153600kB  ‚Üê üö® Usou disco (150MB)!
```

**üí° Compara√ß√£o:**

| Situa√ß√£o | Memory | Disk | Tempo |
|----------|--------|------|-------|
| **Fit in memory** | 50MB | 0 | 120ms ‚úÖ |
| **Spill to disk** | 4MB | 150MB | 5890ms ‚ùå |

**Solu√ß√£o:**

```sql
-- Aumentar work_mem (por sess√£o)
SET work_mem = '256MB';

-- Executar query novamente
EXPLAIN ANALYZE SELECT ...;

-- Se melhorou, considere aumentar globalmente (DBA)
-- ALTER SYSTEM SET work_mem = '128MB';
```

---

### 2.4: Motion Excessivo

**Motion move dados pela rede entre segmentos (caro!):**

```sql
EXPLAIN ANALYZE
SELECT r.nome_regiao, COUNT(*), SUM(v.valor)
FROM vendas_exemplo v
JOIN regioes r ON v.regiao_id = r.regiao_id
GROUP BY r.nome_regiao;
```

**üìä Problema (muitos motions):**

```
HashAggregate
  ->  Redistribute Motion 2:2  (actual time=890.123..1234.567 rows=50000 loops=1)
        Hash Key: r.nome_regiao
        ->  Hash Join
              Hash Cond: (v.regiao_id = r.regiao_id)
              ->  Redistribute Motion 2:2  (actual time=456.789..678.901 rows=100000)  ‚Üê Motion 1
              ->  Broadcast Motion 1:2  (actual time=123.456..125.678 rows=10)  ‚Üê Motion 2
```

**üö® Problema:** 2 motions movendo 100k + 10 linhas

**Tempo gasto em motions:** ~1500ms de 2500ms total (60%!)

**Solu√ß√µes:**

1. **Replicate dimens√£o pequena (regioes)**
   ```sql
   CREATE TABLE regioes (...) DISTRIBUTED REPLICATED;
   -- Elimina Broadcast Motion!
   ```

2. **Co-locate fato e dimens√£o**
   ```sql
   CREATE TABLE vendas (...) DISTRIBUTED BY (regiao_id);
   CREATE TABLE regioes (...) DISTRIBUTED BY (regiao_id);
   -- Elimina Redistribute Motion!
   ```

---

## 3. Otimiza√ß√µes Comuns

### 3.1: Filtrar Antes de JOIN

**‚ùå ERRADO (JOIN depois filtra):**

```sql
SELECT v.*, c.nome
FROM vendas v
JOIN clientes c ON v.cliente_id = c.cliente_id
WHERE v.data_venda >= '2024-01-01'
  AND c.ativo = true;
```

**‚úÖ CORRETO (filtra antes do JOIN):**

```sql
SELECT v.*, c.nome
FROM (
    SELECT * FROM vendas 
    WHERE data_venda >= '2024-01-01'
) v
JOIN (
    SELECT cliente_id, nome FROM clientes 
    WHERE ativo = true
) c ON v.cliente_id = c.cliente_id;
```

**üí° Benef√≠cio:** Menos linhas no JOIN ‚Üí Mais r√°pido!

**Exemplo pr√°tico:**

```sql
-- Teste 1: SEM filtro pr√©vio
EXPLAIN ANALYZE
SELECT COUNT(*)
FROM vendas_exemplo v
JOIN clientes c ON v.cliente_id = c.cliente_id
WHERE v.data_venda >= '2024-06-01';
```

```sql
-- Teste 2: COM filtro pr√©vio (CTE)
EXPLAIN ANALYZE
WITH vendas_filtradas AS (
    SELECT * FROM vendas_exemplo 
    WHERE data_venda >= '2024-06-01'
)
SELECT COUNT(*)
FROM vendas_filtradas v
JOIN clientes c ON v.cliente_id = c.cliente_id;
```

**üìä Compara√ß√£o:**
- Teste 1: 450ms (JOIN com 100k linhas)
- Teste 2: 180ms (JOIN com 8k linhas) ‚Üê **2.5x mais r√°pido!**

---

### 3.2: Usar Subqueries Correlatas com Cuidado

**‚ùå ERRADO (subquery correlata lenta):**

```sql
-- Nested Loop executado 100k vezes!
SELECT v.venda_id, v.valor,
    (SELECT MAX(valor) FROM vendas_exemplo WHERE cliente_id = v.cliente_id) AS max_cliente
FROM vendas_exemplo v
WHERE v.data_venda >= '2024-01-01';
```

**‚úÖ CORRETO (JOIN ou window function):**

```sql
-- Op√ß√£o 1: JOIN
SELECT v.venda_id, v.valor, m.max_valor
FROM vendas_exemplo v
JOIN (
    SELECT cliente_id, MAX(valor) AS max_valor
    FROM vendas_exemplo
    GROUP BY cliente_id
) m ON v.cliente_id = m.cliente_id
WHERE v.data_venda >= '2024-01-01';
```

```sql
-- Op√ß√£o 2: Window Function (mais elegante)
SELECT 
    venda_id, 
    valor,
    MAX(valor) OVER (PARTITION BY cliente_id) AS max_cliente
FROM vendas_exemplo
WHERE data_venda >= '2024-01-01';
```

---

### 3.3: Evitar SELECT *

**‚ùå ERRADO (l√™ colunas desnecess√°rias):**

```sql
SELECT * 
FROM vendas_exemplo
WHERE data_venda >= '2024-01-01';
```

**‚úÖ CORRETO (apenas colunas necess√°rias):**

```sql
SELECT venda_id, data_venda, valor
FROM vendas_exemplo
WHERE data_venda >= '2024-01-01';
```

**üí° Benef√≠cio em tabelas AOCO (column-oriented):**
- L√™ apenas 3 colunas (n√£o todas as 20)
- **I/O reduzido em ~85%!**

**Teste pr√°tico:**

```sql
-- Cria tabela AOCO
CREATE TABLE vendas_colunar (
    venda_id BIGINT,
    data_venda DATE,
    cliente_id INTEGER,
    produto_id INTEGER,
    quantidade INTEGER,
    valor NUMERIC(10,2),
    desconto NUMERIC(10,2),
    imposto NUMERIC(10,2),
    -- ... 12 colunas mais
    observacoes TEXT
)
WITH (appendoptimized=true, orientation=column)
DISTRIBUTED BY (venda_id);
```

```sql
-- Teste 1: SELECT *
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM vendas_colunar WHERE data_venda >= '2024-01-01';
-- Buffers: 500 MB lidos

-- Teste 2: SELECT espec√≠fico
EXPLAIN (ANALYZE, BUFFERS)
SELECT venda_id, valor FROM vendas_colunar WHERE data_venda >= '2024-01-01';
-- Buffers: 75 MB lidos  ‚Üê 6.6x menos I/O!
```

---

### 3.4: LIMIT com ORDER BY

**‚ö†Ô∏è CUIDADO: LIMIT sem √≠ndice apropriado pode ser lento:**

```sql
-- Precisa ordenar TUDO antes de pegar TOP 10
SELECT * FROM vendas_exemplo
ORDER BY valor DESC
LIMIT 10;
```

**EXPLAIN mostra:**

```
Limit
  ->  Gather Motion 2:1
        Merge Key: valor DESC
        ->  Limit
              ->  Sort  ‚Üê Ordena localmente em cada segmento
                    ->  Seq Scan  ‚Üê L√™ TODA a tabela!
```

**‚úÖ Otimiza√ß√£o:** Adicionar √≠ndice ou particionar

```sql
-- √çndice descendente
CREATE INDEX idx_vendas_valor_desc ON vendas_exemplo (valor DESC);
ANALYZE vendas_exemplo;

-- Agora usa Index Scan (mais r√°pido)
EXPLAIN ANALYZE
SELECT * FROM vendas_exemplo
ORDER BY valor DESC
LIMIT 10;
```

---

## 4. Configura√ß√µes do Greenplum

### 4.1: work_mem (Mem√≥ria por Opera√ß√£o)

**O que √©:** Mem√≥ria alocada para cada opera√ß√£o (sort, hash, aggregate).

**Padr√£o GP7:** 64MB

**Quando aumentar:**
- Spill to disk frequente
- Queries com grandes agrega√ß√µes
- Sorts complexos

```sql
-- Ver configura√ß√£o atual
SHOW work_mem;

-- Aumentar para sess√£o atual (teste)
SET work_mem = '256MB';

-- Testar query
EXPLAIN ANALYZE SELECT ...;

-- Se melhorou, considere aumentar globalmente (DBA)
-- C√°lculo: (RAM total / max_connections / num_operacoes_paralelas)
```

**‚ö†Ô∏è CUIDADO:** `work_mem` muito alto pode causar OOM!

**Exemplo:**
- 100 conex√µes simult√¢neas
- Cada query com 3 opera√ß√µes que usam work_mem
- work_mem = 1GB
- **Uso m√°ximo:** 100 √ó 3 √ó 1GB = **300GB RAM!**

---

### 4.2: gp_workfile_limit_per_query

**Limite de quanto uma query pode spill para disco:**

```sql
-- Ver limite atual (0 = ilimitado)
SHOW gp_workfile_limit_per_query;

-- Definir limite (previne queries descontroladas)
SET gp_workfile_limit_per_query = '10GB';
```

**üí° Uso:** Previne query descontrolada de encher disco.

---

### 4.3: optimizer (ORCA vs Planner)

**GP7 tem 2 otimizadores:**

| Otimizador | Quando Usar | Vantagens | Limita√ß√µes |
|------------|-------------|-----------|------------|
| **ORCA** (padr√£o) | Queries complexas OLAP | Planos melhores para JOINs m√∫ltiplos | Algumas features SQL n√£o suportadas |
| **Planner** (legacy) | Queries simples, compatibilidade | Suporta todo SQL | Planos sub-√≥timos em queries complexas |

```sql
-- Verificar otimizador atual
SHOW optimizer;

-- For√ßar Planner para uma query
SET optimizer = off;
EXPLAIN ANALYZE SELECT ...;

-- Voltar para ORCA
SET optimizer = on;
```

**üí° Dica:** Se EXPLAIN mostra plano estranho, teste o outro otimizador!

---

### 4.4: enable_* (Controle Fino de Opera√ß√µes)

**Desabilitar opera√ß√µes espec√≠ficas para testes:**

```sql
-- For√ßa Seq Scan (desabilita Index Scan)
SET enable_indexscan = off;

-- For√ßa Hash Join (desabilita Nested Loop)
SET enable_nestloop = off;

-- Desabilita Merge Join
SET enable_mergejoin = off;
```

**üí° Uso:** Debug de planos de execu√ß√£o (qual opera√ß√£o √© mais r√°pida).

---

## 5. Troubleshooting

### Problema 1: Query Lenta sem Motivo Aparente

**Checklist:**

```sql
-- 1. ANALYZE atualizado?
SELECT last_analyze FROM pg_stat_user_tables WHERE tablename = 'vendas';
-- Se > 1 semana: ANALYZE vendas;

-- 2. Partition pruning funcionando?
EXPLAIN SELECT ... WHERE data_venda = '2024-06-01';
-- Deve mostrar: Partitions selected: 1 (out of N)

-- 3. work_mem suficiente?
EXPLAIN ANALYZE SELECT ...;
-- Procure por: "Disk Usage: XXX kB"  ‚Üê Spill!

-- 4. √çndices sendo usados?
EXPLAIN ANALYZE SELECT ... WHERE coluna = valor;
-- Deve mostrar: Index Scan (n√£o Seq Scan)

-- 5. Motion excessivo?
EXPLAIN ANALYZE SELECT ...;
-- Conte Redistribute/Broadcast Motions (< 2 ideal)
```

---

### Problema 2: Plano Diferente em Produ√ß√£o vs Dev

**Causas:**
- Dados em prod s√£o diferentes (volume, distribui√ß√£o)
- Estat√≠sticas desatualizadas
- Configura√ß√µes diferentes (work_mem, optimizer)

**Solu√ß√£o:**

```sql
-- 1. Copie estat√≠sticas de prod para dev
pg_dump --schema-only --table=vendas prod > vendas_schema.sql
pg_dump --data-only --table=pg_statistic prod > vendas_stats.sql
psql dev < vendas_schema.sql
psql dev < vendas_stats.sql

-- 2. Igualar configura√ß√µes
-- Em dev:
SET work_mem = '128MB';  -- Igual a prod
SET optimizer = on;      -- Igual a prod

-- 3. Testar plano
EXPLAIN ANALYZE SELECT ...;
```

---

### Problema 3: Query Matou Segmento (OOM)

**Sintoma:**

```
ERROR:  Interconnect error: Could not connect to segment 2
DETAIL:  System was unable to allocate memory (seg2 host:port pid=12345)
```

**Causas:**
- `work_mem` muito alto
- Query com cartesian product (JOIN sem ON)
- Spill to disk excessivo

**Solu√ß√£o imediata:**

```sql
-- Reduzir work_mem
SET work_mem = '64MB';

-- Adicionar limite
SET statement_mem = '2GB';  -- M√°ximo por query
```

**Preven√ß√£o:**

```sql
-- Configurar limites globais (DBA)
ALTER DATABASE mydb SET statement_mem = '2GB';
ALTER DATABASE mydb SET gp_workfile_limit_per_query = '10GB';
```

---

## üìù Resumo do M√≥dulo

### Comandos de Diagn√≥stico

```sql
-- Plano de execu√ß√£o
EXPLAIN ANALYZE SELECT ...;

-- Estat√≠sticas de √≠ndices
SELECT * FROM pg_stat_user_indexes WHERE tablename = 'tabela';

-- Estat√≠sticas de tabelas
SELECT * FROM pg_stat_user_tables WHERE tablename = 'tabela';

-- Configura√ß√µes atuais
SHOW work_mem;
SHOW optimizer;

-- Sess√£o atual
SET work_mem = '256MB';
SET optimizer = off;
```

### Checklist de Otimiza√ß√£o

**Antes de otimizar:**
- [ ] ANALYZE est√° atualizado? (< 1 semana)
- [ ] Query usa √≠ndices apropriados?
- [ ] Partition pruning est√° funcionando?
- [ ] Estimativas (rows) pr√≥ximas da realidade?

**Durante otimiza√ß√£o:**
- [ ] Identificou gargalo principal (EXPLAIN ANALYZE)?
- [ ] Spill to disk? (aumentar work_mem)
- [ ] Motion excessivo? (revisar distribui√ß√£o/replica√ß√£o)
- [ ] SELECT * desnecess√°rio? (em AOCO)

**Ap√≥s otimiza√ß√£o:**
- [ ] Tempo melhorou significativamente (> 30%)?
- [ ] Query est√° est√°vel (n√£o varia muito)?
- [ ] N√£o causou regress√£o em outras queries?

### Ordem de Otimiza√ß√£o

```
1. SCHEMA DESIGN (distribui√ß√£o, particionamento)
   ‚Üì
2. ANALYZE (estat√≠sticas atualizadas)
   ‚Üì
3. INDEXES (apenas se necess√°rio)
   ‚Üì
4. QUERY REWRITE (filtros, joins, subqueries)
   ‚Üì
5. CONFIGURA√á√ïES (work_mem, optimizer)
```

### Quando Pedir Ajuda de DBA

- [ ] Query usa > 50% CPU/mem√≥ria do cluster
- [ ] Precisa alterar configura√ß√µes globais (ALTER SYSTEM)
- [ ] Precisa adicionar recursos (RAM, segmentos)
- [ ] Query mata segmentos (OOM)
- [ ] Problema persiste ap√≥s todas as otimiza√ß√µes

---

**üéØ Fim dos M√≥dulos de Particionamento, √çndices e Otimiza√ß√£o!**

**Pr√≥ximos passos:**
- Praticar com dados reais do seu sistema
- Monitorar queries lentas (pg_stat_statements)
- Estabelecer rotinas de manuten√ß√£o (VACUUM, ANALYZE)
- Revisar schema design periodicamente
