# M√≥dulo 2: DDL - Cria√ß√£o de Tabelas e Estrat√©gias de Distribui√ß√£o

**Objetivo:** Dominar a cria√ß√£o de tabelas no Greenplum, compreendendo distribui√ß√£o de dados, orienta√ß√£o de armazenamento e compress√£o para otimizar performance.

---

## √çndice
1. [Lab 2.1: Conceitos de Distribui√ß√£o de Dados](#lab-21-conceitos-de-distribui√ß√£o-de-dados-20-25-min)
2. [Lab 2.2: Orienta√ß√£o de Armazenamento (Row vs Column)](#lab-22-orienta√ß√£o-de-armazenamento-row-vs-column-25-30-min)
3. [Lab 2.3: Compress√£o de Dados](#lab-23-compress√£o-de-dados-20-25-min)
4. [Lab 2.4: Cen√°rios Pr√°ticos e Otimiza√ß√£o](#lab-24-cen√°rios-pr√°ticos-e-otimiza√ß√£o-25-30-min)

---

## Lab 2.1: Conceitos de Distribui√ß√£o de Dados (20-25 min)

### Objetivos
- Compreender os tipos de distribui√ß√£o no Greenplum
- Escolher a estrat√©gia adequada de distribui√ß√£o
- Identificar impactos de performance
- Evitar data skew (desbalanceamento de dados)

### Conceitos Abordados
- **DISTRIBUTED BY (colunas):** Distribui√ß√£o por hash em colunas espec√≠ficas
- **DISTRIBUTED RANDOMLY:** Distribui√ß√£o aleat√≥ria
- **DISTRIBUTED REPLICATED:** Tabela replicada em todos os segmentos
- **Data Skew:** Desbalanceamento de dados entre segmentos

### Por que a Distribui√ß√£o Importa?

No Greenplum, os dados s√£o **fisicamente distribu√≠dos** entre m√∫ltiplos segmentos. A escolha da estrat√©gia de distribui√ß√£o afeta diretamente:

- ‚úÖ **Performance de JOINs:** Evita redistribui√ß√£o de dados
- ‚úÖ **Balanceamento de carga:** Distribui processamento uniformemente
- ‚úÖ **Uso de recursos:** Otimiza CPU, mem√≥ria e I/O
- ‚ùå **Data Skew:** Distribui√ß√£o inadequada causa gargalos

---

### Exerc√≠cio 2.1.1: Distribui√ß√£o por Hash (Padr√£o)

**Objetivo:** Criar tabelas com distribui√ß√£o por hash e entender o comportamento padr√£o

**Cen√°rio:** Tabela de vendas com distribui√ß√£o pela chave prim√°ria

**Passos:**

1. Crie uma tabela com distribui√ß√£o expl√≠cita por hash:
```sql
CREATE TABLE vendas_hash (
    venda_id BIGINT,
    data_venda DATE,
    cliente_id INTEGER,
    produto_id INTEGER,
    quantidade INTEGER,
    valor_total NUMERIC(10,2)
)
DISTRIBUTED BY (venda_id);
```

2. Verifique a distribui√ß√£o criada:
```sql
SELECT 
    c.relname as table_name,
    CASE 
        WHEN policytype = 'p' THEN 'HASH DISTRIBUTED'
        WHEN policytype = 'r' THEN 'REPLICATED'
        ELSE 'RANDOM'
    END AS distribution_type,
    array_to_string(distkey, ', ') AS distribution_columns
FROM pg_class c
JOIN pg_namespace n ON n.oid = c.relnamespace
JOIN gp_distribution_policy p ON p.localoid = c.oid
JOIN pg_attribute a ON a.attrelid = c.oid AND a.attnum = ANY(p.distkey)
WHERE c.relname = 'vendas_hash'
  AND n.nspname = 'public';
```

3. Insira dados de teste:
```sql
INSERT INTO vendas_hash 
SELECT 
    i AS venda_id,
    CURRENT_DATE - (i % 365) AS data_venda,
    (i % 1000) + 1 AS cliente_id,
    (i % 100) + 1 AS produto_id,
    (random() * 10)::INTEGER + 1 AS quantidade,
    (random() * 1000)::NUMERIC(10,2) AS valor_total
FROM generate_series(1, 100000) i;
```

4. Verifique a distribui√ß√£o dos dados entre segmentos:
```sql
SELECT 
    gp_segment_id,
    COUNT(*) as total_rows,
    pg_size_pretty(pg_relation_size('vendas_hash')) as segment_size
FROM vendas_hash
GROUP BY gp_segment_id
ORDER BY gp_segment_id;
```

**An√°lise:**
- Os dados est√£o balanceados entre os segmentos?
- Qual o percentual de varia√ß√£o entre segmentos?
- Por que escolhemos `venda_id` como coluna de distribui√ß√£o?

---

### Exerc√≠cio 2.1.2: Distribui√ß√£o Aleat√≥ria

**Objetivo:** Entender quando usar distribui√ß√£o aleat√≥ria

**Cen√°rio:** Tabela de logs sem chave natural √≥bvia

**Passos:**

1. Crie tabela com distribui√ß√£o aleat√≥ria:
```sql
CREATE TABLE logs_sistema (
    log_id BIGSERIAL,
    timestamp TIMESTAMP,
    nivel VARCHAR(10),
    mensagem TEXT,
    usuario VARCHAR(50)
)
DISTRIBUTED RANDOMLY;
```

2. Insira dados:
```sql
INSERT INTO logs_sistema (timestamp, nivel, mensagem, usuario)
SELECT 
    CURRENT_TIMESTAMP - (i || ' seconds')::INTERVAL,
    CASE (i % 4)
        WHEN 0 THEN 'INFO'
        WHEN 1 THEN 'WARNING'
        WHEN 2 THEN 'ERROR'
        ELSE 'DEBUG'
    END,
    'Log message ' || i,
    'user' || (i % 50)
FROM generate_series(1, 50000) i;
```

3. Compare a distribui√ß√£o:
```sql
SELECT 
    gp_segment_id,
    COUNT(*) as total_rows
FROM logs_sistema
GROUP BY gp_segment_id
ORDER BY gp_segment_id;
```

**Quando usar DISTRIBUTED RANDOMLY:**
- ‚úÖ Tabelas staging/tempor√°rias
- ‚úÖ Sem chave natural adequada
- ‚úÖ Tabelas pequenas sem JOINs frequentes
- ‚ùå Tabelas com JOINs frequentes (causa redistribui√ß√£o)

---

### Exerc√≠cio 2.1.3: Tabelas Replicadas

**Objetivo:** Usar replica√ß√£o para otimizar JOINs com tabelas pequenas

**Cen√°rio:** Tabelas dimens√£o pequenas (lookup tables)

**Passos:**

1. Crie tabelas dimens√£o replicadas:
```sql
-- Tabela de produtos (pequena, usada em muitos JOINs)
CREATE TABLE dim_produtos (
    produto_id INTEGER PRIMARY KEY,
    nome_produto VARCHAR(100),
    categoria VARCHAR(50),
    preco_base NUMERIC(10,2)
)
DISTRIBUTED REPLICATED;

-- Tabela de clientes (pequena)
CREATE TABLE dim_clientes (
    cliente_id INTEGER PRIMARY KEY,
    nome_cliente VARCHAR(100),
    cidade VARCHAR(50),
    estado CHAR(2),
    tipo_cliente VARCHAR(20)
)
DISTRIBUTED REPLICATED;
```

2. Insira dados nas dimens√µes:
```sql
INSERT INTO dim_produtos
SELECT 
    i,
    'Produto ' || i,
    'Categoria ' || (i % 10),
    (random() * 1000)::NUMERIC(10,2)
FROM generate_series(1, 100) i;

INSERT INTO dim_clientes
SELECT 
    i,
    'Cliente ' || i,
    'Cidade ' || (i % 50),
    'SP',
    CASE (i % 3)
        WHEN 0 THEN 'VIP'
        WHEN 1 THEN 'Regular'
        ELSE 'Novo'
    END
FROM generate_series(1, 1000) i;
```

3. Verifique que as tabelas est√£o replicadas em todos os segmentos:
```sql
-- Para tabelas replicadas, use a view gp_distribution_policy
SELECT 
    schemaname,
    tablename,
    CASE 
        WHEN policytype = 'r' THEN 'REPLICATED (em todos segmentos)'
        WHEN policytype = 'p' THEN 'HASH DISTRIBUTED'
        ELSE 'RANDOM'
    END AS distribution_type
FROM pg_tables pt
LEFT JOIN gp_distribution_policy gp ON gp.localoid = (schemaname||'.'||tablename)::regclass
WHERE tablename IN ('dim_produtos', 'dim_clientes');

-- Verifique o n√∫mero de segmentos onde a tabela existe
SELECT 
    'dim_produtos' as tabela,
    COUNT(DISTINCT content) as num_segmentos_com_dados
FROM gp_segment_configuration
WHERE role = 'p' AND content >= 0;

-- Compare tamanho: tabela replicada vs distribu√≠da
SELECT 
    tablename,
    pg_size_pretty(pg_relation_size(tablename::regclass)) as size_per_segment,
    pg_size_pretty(pg_total_relation_size(tablename::regclass)) as total_size
FROM (VALUES ('dim_produtos'), ('dim_clientes')) AS t(tablename);
```

**Entendendo Tabelas Replicadas:**
- Cada segmento tem uma c√≥pia completa da tabela
- `pg_relation_size()` mostra tamanho em um segmento
- `pg_total_relation_size()` mostra tamanho total (n √ó tamanho)
- N√£o √© poss√≠vel usar `gp_segment_id` diretamente em tabelas replicadas

4. Teste performance de JOIN (sem redistribui√ß√£o):
```sql
EXPLAIN ANALYZE
SELECT 
    v.venda_id,
    p.nome_produto,
    c.nome_cliente,
    v.quantidade,
    v.valor_total
FROM vendas_hash v
JOIN dim_produtos p ON v.produto_id = p.produto_id
JOIN dim_clientes c ON v.cliente_id = c.cliente_id
WHERE v.data_venda >= CURRENT_DATE - 30
LIMIT 100;
```

**An√°lise do EXPLAIN:**
- H√° "Redistribute Motion" no plano?
- Como a replica√ß√£o evita movimento de dados?

**Quando usar DISTRIBUTED REPLICATED:**
- ‚úÖ Tabelas pequenas (< 10MB geralmente)
- ‚úÖ Tabelas dimens√£o em JOINs frequentes
- ‚úÖ Lookup tables (pa√≠ses, categorias, status)
- ‚ùå Tabelas grandes (desperd√≠cio de espa√ßo)

---

### Exerc√≠cio 2.1.4: Detectando Data Skew

**Objetivo:** Identificar e resolver desbalanceamento de dados

**Cen√°rio:** Distribui√ß√£o inadequada causando skew

**Passos:**

1. Crie tabela com distribui√ß√£o problem√°tica:
```sql
CREATE TABLE vendas_skew (
    venda_id BIGINT,
    data_venda DATE,
    cliente_id INTEGER,
    loja_id INTEGER,  -- Poucas lojas, m√° escolha para distribui√ß√£o
    valor NUMERIC(10,2)
)
DISTRIBUTED BY (loja_id);  -- PROBLEMA: poucas lojas diferentes
```

2. Insira dados desbalanceados:
```sql
INSERT INTO vendas_skew
SELECT 
    i,
    CURRENT_DATE - (i % 365),
    (i % 1000) + 1,
    (i % 5) + 1,  -- Apenas 5 lojas!
    (random() * 1000)::NUMERIC(10,2)
FROM generate_series(1, 100000) i;
```

3. Detecte o skew:
```sql
-- An√°lise detalhada de distribui√ß√£o
SELECT 
    gp_segment_id,
    COUNT(*) as num_rows,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage
FROM vendas_skew
GROUP BY gp_segment_id
ORDER BY gp_segment_id;
```

4. Use a view gp_toolkit para detectar skew:
```sql
SELECT 
    skcnamespace as schema_name,
    skcrelname as table_name,
    skccoeff as skew_coefficient  -- > 0.1 indica problema
FROM gp_toolkit.gp_skew_coefficients
WHERE skcrelname = 'vendas_skew';
```

5. Corrija a distribui√ß√£o:
```sql
-- Recrie a tabela com distribui√ß√£o adequada
CREATE TABLE vendas_corrigida (
    venda_id BIGINT,
    data_venda DATE,
    cliente_id INTEGER,
    loja_id INTEGER,
    valor NUMERIC(10,2)
)
DISTRIBUTED BY (venda_id, cliente_id);  -- M√∫ltiplas colunas

-- Migre os dados
INSERT INTO vendas_corrigida SELECT * FROM vendas_skew;

-- Verifique a melhoria
SELECT 
    gp_segment_id,
    COUNT(*) as num_rows,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage
FROM vendas_corrigida
GROUP BY gp_segment_id
ORDER BY gp_segment_id;
```

**Regras para Escolher Colunas de Distribui√ß√£o:**
1. ‚úÖ Alta cardinalidade (muitos valores distintos)
2. ‚úÖ Usada em JOINs frequentes
3. ‚úÖ Distribui√ß√£o uniforme de valores
4. ‚ùå Evitar colunas com poucos valores distintos
5. ‚ùå Evitar colunas com valores NULL frequentes

---

## Lab 2.2: Orienta√ß√£o de Armazenamento (Row vs Column) (25-30 min)

### Objetivos
- Compreender armazenamento orientado a linha vs coluna
- Escolher orienta√ß√£o adequada ao caso de uso
- Medir impacto de performance

### Conceitos Abordados
- **Row-Oriented (Heap):** Armazenamento tradicional, linha por linha
- **Column-Oriented (AO/AOCO):** Armazenamento colunar, otimizado para analytics
- **Append-Optimized (AO):** Tabelas de inser√ß√£o em massa
- **Compress√£o:** Mais efetiva em storage colunar

---

### Exerc√≠cio 2.2.1: Tabela Orientada a Linha (Heap - Padr√£o)

**Objetivo:** Entender o comportamento padr√£o do armazenamento

**Cen√°rio:** Tabela transacional com UPDATEs frequentes

**Passos:**

1. Crie tabela heap (orientada a linha):
```sql
CREATE TABLE transacoes_heap (
    transacao_id BIGSERIAL,
    conta_id INTEGER,
    tipo_transacao VARCHAR(20),
    valor NUMERIC(15,2),
    data_transacao TIMESTAMP,
    status VARCHAR(20),
    descricao TEXT
)
DISTRIBUTED BY (transacao_id);
-- Sem WITH, o padr√£o √© HEAP (row-oriented)
```

2. Verifique o tipo de armazenamento:
```sql
-- No Greenplum 7.x, usar pg_class.relam para identificar tipo de storage
SELECT 
    c.relname AS table_name,
    CASE 
        WHEN am.amname = 'heap' THEN 'HEAP (Row-Oriented)'
        WHEN am.amname = 'ao_row' THEN 'Append-Optimized Row'
        WHEN am.amname = 'ao_column' THEN 'Append-Optimized Column'
        ELSE 'Other: ' || COALESCE(am.amname, 'unknown')
    END AS storage_type,
    COALESCE(
        (SELECT option_value 
         FROM pg_options_to_table(c.reloptions) 
         WHERE option_name = 'compresstype'), 
        'none'
    ) AS compression_type
FROM pg_class c
JOIN pg_namespace n ON n.oid = c.relnamespace
LEFT JOIN pg_am am ON c.relam = am.oid
WHERE c.relname = 'transacoes_heap'
  AND n.nspname = 'public';
```

**Entendendo a Query:**
- **pg_am (Access Method):** Define o m√©todo de acesso/storage da tabela
  - `heap` = tabela tradicional row-oriented
  - `ao_row` = append-optimized row-oriented
  - `ao_column` = append-optimized column-oriented
- **reloptions:** Op√ß√µes de armazenamento (compress√£o, etc)
- **pg_options_to_table:** Fun√ß√£o que parseia as op√ß√µes de reloptions

3. Insira dados e me√ßa o tamanho:
```sql
INSERT INTO transacoes_heap (conta_id, tipo_transacao, valor, data_transacao, status, descricao)
SELECT 
    (random() * 10000)::INTEGER,
    CASE (random() * 4)::INTEGER
        WHEN 0 THEN 'DEPOSITO'
        WHEN 1 THEN 'SAQUE'
        WHEN 2 THEN 'TRANSFERENCIA'
        ELSE 'PAGAMENTO'
    END,
    (random() * 10000)::NUMERIC(15,2),
    CURRENT_TIMESTAMP - (random() * 365)::INTEGER * INTERVAL '1 day',
    CASE (random() * 3)::INTEGER
        WHEN 0 THEN 'CONCLUIDO'
        WHEN 1 THEN 'PENDENTE'
        ELSE 'CANCELADO'
    END,
    'Transacao ID ' || i
FROM generate_series(1, 1000000) i;

-- Tamanho da tabela
SELECT pg_size_pretty(pg_total_relation_size('transacoes_heap'));
```

4. Teste UPDATE (eficiente em HEAP):
```sql
EXPLAIN ANALYZE
UPDATE transacoes_heap 
SET status = 'PROCESSADO' 
WHERE transacao_id BETWEEN 1000 AND 2000;
```

**Interpretando o resultado do EXPLAIN:**

```
                                                        QUERY PLAN
------------------------------------------------------------------------------------------------------------------------
 Update on transacoes_heap  (cost=0.00..592.87 rows=495 width=1) (actual time=0.000..61.614 rows=0 loops=1)
   ->  Seq Scan on transacoes_heap  (cost=0.00..473.08 rows=989 width=64) (actual time=59.072..59.182 rows=506 loops=1)
         Filter: ((transacao_id >= 1000) AND (transacao_id <= 2000))
         Rows Removed by Filter: 499257
 Optimizer: GPORCA
 Planning Time: 6.216 ms
   (slice0)    Executor memory: 41K bytes avg x 2 workers, 41K bytes max (seg0).
 Memory used:  128000kB
 Execution Time: 62.617 ms
```

**An√°lise detalhada:**

1. **Update on transacoes_heap** - Opera√ß√£o de UPDATE
   - `actual time=0.000..61.614 rows=0` - UPDATE n√£o retorna linhas (rows=0 √© normal)
   - Tempo real: 61.614ms para completar a opera√ß√£o

2. **Seq Scan on transacoes_heap** - Varredura sequencial da tabela
   - `rows=989` (estimativa) vs `rows=506` (real) - Estimativa do otimizador foi 2x maior
   - `actual time=59.072..59.182` - Tempo real de scan: ~59ms (maior parte do tempo total)
   - `width=64` - Largura m√©dia da linha em bytes

3. **Filter: (transacao_id >= 1000 AND transacao_id <= 2000)**
   - Filtro aplicado durante o scan
   - **Rows Removed by Filter: 499257** - Das ~500k linhas totais, removeu 499.257
   - Apenas 506 linhas atenderam o crit√©rio (foram atualizadas)
   - **Seletividade: ~0.1%** (506/500000) - Query muito seletiva!

4. **M√©tricas de Performance:**
   - `Planning Time: 6.216 ms` - Tempo para gerar o plano de execu√ß√£o
   - `Execution Time: 62.617 ms` - Tempo total de execu√ß√£o
   - `Memory used: 128000kB` (~125MB) - Mem√≥ria consumida
   - `Optimizer: GPORCA` - Otimizador utilizado

**Por que √© positivo para HEAP?**

‚úÖ **UPDATE in-place eficiente:** Tabelas HEAP permitem UPDATE diretamente no local (in-place), ao contr√°rio de AO tables que precisariam reescrever dados

‚úÖ **Tempo de execu√ß√£o aceit√°vel:** 62ms para atualizar 506 linhas em uma tabela de 500k √© r√°pido

‚úÖ **Baixo uso de mem√≥ria:** Apenas 125MB de mem√≥ria para processar

‚úÖ **MVCC (Multi-Version Concurrency Control):** HEAP suporta MVCC nativamente, permitindo:
   - Leituras simult√¢neas durante UPDATE
   - Sem lock de leitura
   - Rollback eficiente

‚ö†Ô∏è **Ponto de Discuss√£o!**
- **Seq Scan em tabela grande:** Para 500k linhas, varreu toda tabela
- **Solu√ß√£o:** Se UPDATEs por `transacao_id` forem frequentes, considere criar √≠ndice:
  ```sql
  CREATE INDEX idx_transacao_id ON transacoes_heap(transacao_id);
  ```
  Isso mudaria de Seq Scan para Index Scan quando seletividade < 5%


**Quando usar HEAP (Row-Oriented):**
- ‚úÖ Tabelas com UPDATEs e DELETEs frequentes
- ‚úÖ Queries que acessam maioria das colunas
- ‚úÖ Tabelas transacionais (OLTP)
- ‚úÖ Tabelas pequenas
- ‚ùå An√°lises que leem poucas colunas de muitas linhas

---

### Exerc√≠cio 2.2.2: Tabela Append-Optimized Row (AO)

**Objetivo:** Usar tabelas append-optimized para cargas em massa

**Cen√°rio:** Tabela com inser√ß√µes batch, sem updates, que utilizam a linha completa.

**Passos:**

1. Crie tabela AO row-oriented:
```sql
CREATE TABLE stg_vendas_ao (
    venda_id BIGINT,
    data_venda DATE,
    loja_id INTEGER,
    produto_id INTEGER,
    cliente_id INTEGER,
    quantidade INTEGER,
    valor_unitario NUMERIC(10,2),
    valor_total NUMERIC(12,2),
    custo_produto NUMERIC(10,2),
    margem NUMERIC(10,2)
)
WITH (appendoptimized=true, orientation=row)
DISTRIBUTED BY (venda_id);
```

2. Insira dados e compare tamanho:
```sql
INSERT INTO stg_vendas_ao
SELECT 
    i,
    CURRENT_DATE - (random() * 365)::INTEGER,
    (random() * 100)::INTEGER + 1,
    (random() * 1000)::INTEGER + 1,
    (random() * 10000)::INTEGER + 1,
    (random() * 10)::INTEGER + 1,
    (random() * 1000)::NUMERIC(10,2),
    0,  -- ser√° calculado
    (random() * 500)::NUMERIC(10,2),
    0   -- ser√° calculado
FROM generate_series(1, 1000000) i;
```

```sql
-- Atualiza valores calculados (LENTO em AO!)
UPDATE stg_vendas_ao 
SET valor_total = quantidade * valor_unitario,
    margem = (quantidade * valor_unitario) - (quantidade * custo_produto);
```
```sql
-- Tamanho
SELECT pg_size_pretty(pg_total_relation_size('stg_vendas_ao'));
```

**Caracter√≠sticas do AO Row:**
- ‚úÖ Melhor compress√£o que HEAP
- ‚úÖ Inser√ß√µes batch eficientes
- ‚úÖ Queries que leem linha completa
- ‚ùå UPDATEs muito lentos (marca dele√ß√£o + insere nova linha)
- ‚ùå VACUUMs necess√°rios ap√≥s updates/deletes

---

### Exerc√≠cio 2.2.3: Tabela Append-Optimized Column (AOCO)

**Objetivo:** Otimizar queries anal√≠ticas com storage colunar

**Cen√°rio:** Data warehouse, an√°lises agregadas

**Passos:**

1. Crie tabela AOCO (orientada a coluna):
```sql
CREATE TABLE fatos_vendas_aoco (
    venda_id BIGINT,
    data_venda DATE,
    loja_id INTEGER,
    produto_id INTEGER,
    cliente_id INTEGER,
    quantidade INTEGER,
    valor_unitario NUMERIC(10,2),
    valor_total NUMERIC(12,2),
    custo_produto NUMERIC(10,2),
    margem NUMERIC(10,2)
)
WITH (appendoptimized=true, orientation=column)
DISTRIBUTED BY (venda_id);
```

2. Insira os mesmos dados:
```sql
INSERT INTO fatos_vendas_aoco
SELECT * FROM stg_vendas_ao;

-- Compare tamanhos
SELECT 
    'AO Row' as table_type,
    pg_size_pretty(pg_total_relation_size('stg_vendas_ao')) as size
UNION ALL
SELECT 
    'AOCO Column',
    pg_size_pretty(pg_total_relation_size('fatos_vendas_aoco'));
```

3. Teste query anal√≠tica (l√™ poucas colunas):
```sql
-- Query em tabela AO Row
EXPLAIN ANALYZE
SELECT 
    data_venda,
    SUM(valor_total) as total_vendas,
    AVG(margem) as margem_media,
    COUNT(*) as qtd_vendas
FROM fatos_vendas_ao
WHERE data_venda >= CURRENT_DATE - 90
GROUP BY data_venda
ORDER BY data_venda;

-- Mesma query em tabela AOCO
EXPLAIN ANALYZE
SELECT 
    data_venda,
    SUM(valor_total) as total_vendas,
    AVG(margem) as margem_media,
    COUNT(*) as qtd_vendas
FROM fatos_vendas_aoco
WHERE data_venda >= CURRENT_DATE - 90
GROUP BY data_venda
ORDER BY data_venda;
```

4. Compare I/O nas queries:
```sql
-- An√°lise de colunas acessadas em AOCO
SELECT 
    a.attname as column_name,
    pg_size_pretty(pg_column_size(a.attname::text)::bigint) as column_size
FROM pg_attribute a
JOIN pg_class c ON a.attrelid = c.oid
WHERE c.relname = 'fatos_vendas_aoco'
  AND a.attnum > 0
ORDER BY a.attnum;
```

**Quando usar AOCO (Column-Oriented):**
- ‚úÖ Data Warehouse / Analytics
- ‚úÖ Queries que leem poucas colunas
- ‚úÖ Agrega√ß√µes e scans grandes
- ‚úÖ Alta taxa de compress√£o
- ‚úÖ Tabelas largas (muitas colunas)
- ‚ùå Queries que precisam de linha completa
- ‚ùå UPDATEs frequentes
- ‚ùå Tabelas transacionais

---

### Exerc√≠cio 2.2.4: Compara√ß√£o de Performance

**Objetivo:** Medir diferen√ßas reais de performance

**Passos:**

1. Crie vers√µes das tr√™s orienta√ß√µes:
```sql
-- J√° temos: transacoes_heap, fatos_vendas_ao, fatos_vendas_aoco

-- Crie vers√£o HEAP da tabela de fatos
CREATE TABLE fatos_vendas_heap AS 
SELECT * FROM fatos_vendas_aoco
DISTRIBUTED BY (venda_id);
```

2. Teste 1 - Query seletiva (poucas colunas):
```sql
-- HEAP
EXPLAIN (ANALYZE, BUFFERS)
SELECT loja_id, SUM(valor_total) 
FROM fatos_vendas_heap 
WHERE data_venda >= CURRENT_DATE - 30
GROUP BY loja_id;
```
```sql
-- AO Row
EXPLAIN (ANALYZE, BUFFERS)
SELECT loja_id, SUM(valor_total) 
FROM fatos_vendas_ao 
WHERE data_venda >= CURRENT_DATE - 30
GROUP BY loja_id;
```
```sql
-- AOCO Column
EXPLAIN (ANALYZE, BUFFERS)
SELECT loja_id, SUM(valor_total) 
FROM fatos_vendas_aoco 
WHERE data_venda >= CURRENT_DATE - 30
GROUP BY loja_id;
```

3. Teste 2 - Query que acessa todas as colunas:
```sql
-- Teste em todas as tr√™s tabelas
EXPLAIN ANALYZE
SELECT * FROM fatos_vendas_heap WHERE venda_id < 1000;
```
```sql
EXPLAIN ANALYZE
SELECT * FROM fatos_vendas_ao WHERE venda_id < 1000;
```
```sql
EXPLAIN ANALYZE
SELECT * FROM fatos_vendas_aoco WHERE venda_id < 1000;
```

**M√©tricas para Comparar:**
- Tempo de execu√ß√£o (Execution Time)
- Quantidade de dados lidos (rows/bytes)
- Uso de mem√≥ria (Peak Memory)

---

## Lab 2.3: Compress√£o de Dados (20-25 min)

### Objetivos
- Aplicar diferentes algoritmos de compress√£o
- Balancear compress√£o vs performance
- Compress√£o por coluna em AOCO

### Conceitos Abordados
- **Algoritmos:** zlib, zstd, rle_type, none
- **Compression level:** 1-9 (trade-off espa√ßo/CPU)
- **Column-level compression:** Diferentes algoritmos por coluna

---

### Exerc√≠cio 2.3.1: Compress√£o em Tabelas AO

**Objetivo:** Aplicar compress√£o e medir ganhos

**Passos:**

1. Crie tabelas com diferentes compress√µes:
```sql
-- Sem compress√£o
CREATE TABLE vendas_nocomp (
    venda_id BIGINT,
    data_venda DATE,
    cliente_id INTEGER,
    produto_id INTEGER,
    valor NUMERIC(12,2),
    descricao TEXT
)
WITH (appendoptimized=true, orientation=row, compresstype=none)
DISTRIBUTED BY (venda_id);
```
```sql
-- Compress√£o zlib (padr√£o, balanceado)
CREATE TABLE vendas_zlib (
    venda_id BIGINT,
    data_venda DATE,
    cliente_id INTEGER,
    produto_id INTEGER,
    valor NUMERIC(12,2),
    descricao TEXT
)
WITH (appendoptimized=true, orientation=row, compresstype=zlib, compresslevel=5)
DISTRIBUTED BY (venda_id);
```
```sql
-- Compress√£o zstd (mais recente, melhor em GP7+)
CREATE TABLE vendas_zstd (
    venda_id BIGINT,
    data_venda DATE,
    cliente_id INTEGER,
    produto_id INTEGER,
    valor NUMERIC(12,2),
    descricao TEXT
)
WITH (appendoptimized=true, orientation=row, compresstype=zstd, compresslevel=5)
DISTRIBUTED BY (venda_id);
```

2. Insira mesmos dados em todas:
```sql
INSERT INTO vendas_nocomp
SELECT 
    i,
    CURRENT_DATE - (i % 365),
    (random() * 10000)::INTEGER,
    (random() * 1000)::INTEGER,
    (random() * 1000)::NUMERIC(12,2),
    'Venda produto ' || (i % 100) || ' quantidade ' || (i % 10) || ' descricao repetida para aumentar compressao'
FROM generate_series(1, 5000000) i;
```
```sql
INSERT INTO vendas_zlib SELECT * FROM vendas_nocomp;
```
```sql
INSERT INTO vendas_zstd SELECT * FROM vendas_nocomp;
```

3. Compare tamanhos e taxa de compress√£o:
```sql
SELECT 
    tablename,
    pg_size_pretty(pg_total_relation_size(tablename::regclass)) as total_size,
    pg_total_relation_size(tablename::regclass) as size_bytes,
    ROUND(100.0 - (pg_total_relation_size(tablename::regclass) * 100.0 / 
          pg_total_relation_size('vendas_nocomp')), 2) as compression_percent
FROM (
    VALUES ('vendas_nocomp'), ('vendas_zlib'), ('vendas_zstd')
) AS t(tablename)
ORDER BY size_bytes DESC;
```

4. Compare performance de leitura:
```sql
-- Sem compress√£o
EXPLAIN ANALYZE
SELECT COUNT(*), SUM(valor) FROM vendas_nocomp WHERE data_venda >= CURRENT_DATE - 30;
```
```sql
-- Com zlib
EXPLAIN ANALYZE
SELECT COUNT(*), SUM(valor) FROM vendas_zlib WHERE data_venda >= CURRENT_DATE - 30;
```
```sql
-- Com zstd
EXPLAIN ANALYZE
SELECT COUNT(*), SUM(valor) FROM vendas_zstd WHERE data_venda >= CURRENT_DATE - 30;
```

**An√°lise:**
- Qual teve melhor taxa de compress√£o?
- O overhead de CPU afetou significativamente a query?
- Quando vale a pena usar compress√£o m√°xima (level 9)?

---

### Exerc√≠cio 2.3.2: Compress√£o por Coluna (AOCO)

**Objetivo:** Otimizar compress√£o escolhendo algoritmo por coluna

**Cen√°rio:** Tabela com colunas de diferentes tipos e padr√µes

**Passos:**

1. Crie tabela AOCO com compress√£o por coluna:
```sql
CREATE TABLE vendas_detalhadas (
    venda_id BIGINT ENCODING (compresstype=zstd, compresslevel=7),  -- IDs: alta compress√£o
    data_venda DATE ENCODING (compresstype=rle_type),  -- Datas: RLE eficiente
    hora_venda TIME ENCODING (compresstype=zlib),
    cliente_id INTEGER ENCODING (compresstype=zstd, compresslevel=5),
    cliente_nome VARCHAR(100) ENCODING (compresstype=zlib, compresslevel=6),
    produto_id INTEGER ENCODING (compresstype=zstd, compresslevel=5),
    produto_nome VARCHAR(200) ENCODING (compresstype=zlib, compresslevel=6),
    categoria VARCHAR(50) ENCODING (compresstype=rle_type),  -- Poucos valores: RLE
    quantidade INTEGER ENCODING (compresstype=zlib),
    valor_unitario NUMERIC(10,2) ENCODING (compresstype=zlib),
    valor_total NUMERIC(12,2) ENCODING (compresstype=zlib),
    status VARCHAR(20) ENCODING (compresstype=rle_type),  -- Status limitados: RLE
    observacoes TEXT ENCODING (compresstype=zlib, compresslevel=7)  -- Texto: alta compress√£o
)
WITH (appendoptimized=true, orientation=column)
DISTRIBUTED BY (venda_id);
```

2. Insira dados variados:
```sql
INSERT INTO vendas_detalhadas
SELECT 
    i,
    CURRENT_DATE,
    ('08:00:00'::TIME + (i % 86400 || ' seconds')::INTERVAL)::TIME,
    (i % 5000) + 1,
    'Cliente Nome ' || ((i % 5000) + 1),
    (i % 200) + 1,
    'Produto Nome ' || ((i % 200) + 1),
    'VENDA',  
    (random() * 10)::INTEGER + 1,
    (random() * 500)::NUMERIC(10,2),
    0,
    'CONCLUIDO',
    'Observacao da venda numero ' || i || ' com detalhes adicionais para aumentar volume de texto'
FROM generate_series(1, 1000000) i;
```

3. Analise compress√£o por coluna:
```sql
SELECT 
    a.attname as column_name,
    t.typname as data_type,
    CASE 
        WHEN ae.attoptions IS NOT NULL THEN
            (SELECT option_value 
             FROM unnest(ae.attoptions) AS option(option_value)
             WHERE option_value LIKE 'compresstype=%'
             LIMIT 1)
        ELSE 'none'
    END as compression_type,
    CASE 
        WHEN ae.attoptions IS NOT NULL THEN
            (SELECT option_value 
             FROM unnest(ae.attoptions) AS option(option_value)
             WHERE option_value LIKE 'compresslevel=%'
             LIMIT 1)
        ELSE NULL
    END as compression_level
FROM pg_attribute a
JOIN pg_class c ON a.attrelid = c.oid
JOIN pg_type t ON a.atttypid = t.oid
LEFT JOIN pg_attribute_encoding ae ON ae.attrelid = a.attrelid AND ae.attnum = a.attnum
WHERE c.relname = 'vendas_detalhadas'
  AND a.attnum > 0
  AND NOT a.attisdropped
ORDER BY a.attnum;
```

4. Crie vers√£o sem otimiza√ß√£o para comparar:
```sql
-- Vers√£o com compress√£o uniforme
CREATE TABLE vendas_detalhadas_simples (
    venda_id BIGINT,
    data_venda DATE,
    hora_venda TIME,
    cliente_id INTEGER,
    cliente_nome VARCHAR(100),
    produto_id INTEGER,
    produto_nome VARCHAR(200),
    categoria VARCHAR(50),
    quantidade INTEGER,
    valor_unitario NUMERIC(10,2),
    valor_total NUMERIC(12,2),
    status VARCHAR(20),
    observacoes TEXT
)
WITH (appendoptimized=true, orientation=column, compresstype=zlib, compresslevel=5)
DISTRIBUTED BY (venda_id);
```
```sql

INSERT INTO vendas_detalhadas_simples SELECT * FROM vendas_detalhadas;
```
```sql
-- Compare tamanhos
SELECT 
    'Otimizada por coluna' as version,
    pg_size_pretty(pg_total_relation_size('vendas_detalhadas')) as size
UNION ALL
SELECT 
    'Compressao uniforme',
    pg_size_pretty(pg_total_relation_size('vendas_detalhadas_simples'));
```

5. A import√¢ncia de entender o comportamento dos dados!

```sql
-- Vamos fazer agora uma atualiza√ß√£o nos dados da tabela
UPDATE vendas_detalhadas SET valor_total = quantidade * valor_unitario;
```
```sql
-- Verificar novamente os tamanhos:
SELECT 
    'Otimizada por coluna' as version,
    pg_size_pretty(pg_total_relation_size('vendas_detalhadas')) as size
UNION ALL
SELECT 
    'Compressao uniforme',
    pg_size_pretty(pg_total_relation_size('vendas_detalhadas_simples'));
```
**O que aconteceu??**
- **Registros 'mortos** Algumas opera√ß√µes deixam registros 'mortos' pra tr√°s nas tabelas, e esses registros continuam ocupando espa√ßo, e esse espa√ßo vai prejudicar a performance geral!
- **Vacuum** mais pra frente vamos ver os conceitos de Vacuum, que v√£o ajudar a liberar esse espa√ßo morto das tabelas.
```sql
-- Verificando registros mortos
SELECT 
    schemaname,
    relname,
    n_live_tup as linhas_vivas,
    n_dead_tup as linhas_mortas,
    last_vacuum,
    last_autovacuum
FROM pg_stat_user_tables
WHERE relname IN ('vendas_detalhadas');
```


**Estrat√©gias de Compress√£o por Tipo de Coluna:**
- **IDs num√©ricos:** zstd level 5-7
- **Datas/Timestamps:** rle_type (valores repetidos)
- **Status/Categorias:** rle_type (cardinalidade baixa)
- **Texto/VARCHAR:** zlib level 5-7
- **N√∫meros/decimais:** zlib level 3-5
- **Colunas √∫nicas:** compresstype=none (n√£o comprimem bem)

---

### Exerc√≠cio 2.3.3: Impact Trade-offs

**Objetivo:** Entender trade-offs entre compress√£o e performance

**Passos:**

1. Crie tabelas com diferentes n√≠veis de compress√£o:
```sql
-- Compress√£o baixa (r√°pida)
CREATE TABLE metrics_comp1 (
    id BIGINT,
    timestamp TIMESTAMP,
    metric_value DOUBLE PRECISION,
    metadata TEXT
)
WITH (appendoptimized=true, orientation=column, compresstype=zlib, compresslevel=1)
DISTRIBUTED BY (id);
```
```sql
-- Compress√£o alta (m√°xima)
CREATE TABLE metrics_comp9 (
    id BIGINT,
    timestamp TIMESTAMP,
    metric_value DOUBLE PRECISION,
    metadata TEXT
)
WITH (appendoptimized=true, orientation=column, compresstype=zlib, compresslevel=9)
DISTRIBUTED BY (id);
```

2. Me√ßa tempo de INSERT:
```sql
-- Level 1
\timing on
```
```sql
INSERT INTO metrics_comp1
SELECT 
    i,
    CURRENT_TIMESTAMP - (i || ' seconds')::INTERVAL,
    random() * 1000,
    'Metadata texto repetido ' || (i % 100)
FROM generate_series(1, 1000000) i;
```
```sql
-- Level 9
INSERT INTO metrics_comp9
SELECT * FROM metrics_comp1;
```
```sql
\timing off
```

3. Compare tamanho vs tempo:
```sql
SELECT 
    tablename,
    pg_size_pretty(pg_total_relation_size(tablename::regclass)) as size,
    'Check insert time from output above' as insert_time
FROM (
    VALUES ('metrics_comp1'), ('metrics_comp9')
) AS t(tablename);
```


---

## Lab 2.4: Cen√°rios Pr√°ticos e Otimiza√ß√£o (25-30 min)

### Objetivos
- Aplicar conhecimentos em cen√°rios reais
- Tomar decis√µes de design
- Otimizar tabelas existentes

---

### Exerc√≠cio 2.4.1: Cen√°rio 1 - E-commerce (Fatos de Vendas)

**Contexto:**
- 10 milh√µes de vendas/m√™s
- Queries anal√≠ticas: vendas por per√≠odo, produto, regi√£o
- Inser√ß√£o batch di√°ria
- Sem updates ap√≥s inser√ß√£o
- Reten√ß√£o: 5 anos

**Qual melhor modelo?**

**Solu√ß√£o Proposta:**
```sql
CREATE TABLE fato_vendas_ecommerce (
    venda_id BIGINT,
    data_venda DATE,
    data_entrega DATE,
    cliente_id INTEGER,
    produto_id INTEGER,
    loja_id SMALLINT,
    regiao_id SMALLINT,
    quantidade SMALLINT,
    valor_unitario NUMERIC(10,2),
    valor_total NUMERIC(12,2),
    desconto NUMERIC(10,2),
    frete NUMERIC(10,2),
    imposto NUMERIC(10,2),
    custo_produto NUMERIC(10,2),
    margem_lucro NUMERIC(12,2),
    forma_pagamento VARCHAR(30),
    status_pedido VARCHAR(20),
    canal_venda VARCHAR(20)
)
WITH (
    appendoptimized=true,
    orientation=column,
    compresstype=zstd,
    compresslevel=5
)
DISTRIBUTED BY (venda_id)
PARTITION BY RANGE (data_venda)
(
    START ('2020-01-01'::DATE) END ('2025-12-31'::DATE) EVERY (INTERVAL '1 month')
);
```
```sql
-- Otimiza√ß√µes espec√≠ficas de coluna
ALTER TABLE fato_vendas_ecommerce 
    ALTER COLUMN data_venda SET ENCODING (compresstype=rle_type),
    ALTER COLUMN regiao_id SET ENCODING (compresstype=rle_type),
    ALTER COLUMN loja_id SET ENCODING (compresstype=rle_type),
    ALTER COLUMN forma_pagamento SET ENCODING (compresstype=rle_type),
    ALTER COLUMN status_pedido SET ENCODING (compresstype=rle_type),
    ALTER COLUMN canal_venda SET ENCODING (compresstype=rle_type);
```

**Justificativas:**
- ‚úÖ **AOCO:** Queries anal√≠ticas, l√™ poucas colunas
- ‚úÖ **DISTRIBUTED BY (venda_id):** Alta cardinalidade, √∫nica
- ‚úÖ **zstd:** Boa compress√£o, performance GP7+
- ‚úÖ **RLE em colunas repetitivas:** Status, categorias, datas
- ‚úÖ **PARTITION:** Gest√£o eficiente, drop de parti√ß√µes antigas

**Teste a solu√ß√£o:**
```sql
-- Insira dados de exemplo
INSERT INTO fato_vendas_ecommerce
SELECT 
    i,
    CURRENT_DATE - (random() * 1825)::INTEGER,
    CURRENT_DATE - (random() * 1800)::INTEGER,
    (random() * 100000)::INTEGER,
    (random() * 5000)::INTEGER,
    (random() * 50)::SMALLINT + 1,
    (random() * 10)::SMALLINT + 1,
    (random() * 5)::SMALLINT + 1,
    (random() * 500)::NUMERIC(10,2),
    0,
    (random() * 50)::NUMERIC(10,2),
    (random() * 30)::NUMERIC(10,2),
    0,
    (random() * 200)::NUMERIC(10,2),
    0,
    CASE (random() * 4)::INTEGER
        WHEN 0 THEN 'CARTAO_CREDITO'
        WHEN 1 THEN 'CARTAO_DEBITO'
        WHEN 2 THEN 'PIX'
        ELSE 'BOLETO'
    END,
    CASE (random() * 5)::INTEGER
        WHEN 0 THEN 'ENTREGUE'
        WHEN 1 THEN 'EM_TRANSITO'
        WHEN 2 THEN 'PROCESSANDO'
        WHEN 3 THEN 'CANCELADO'
        ELSE 'PENDENTE'
    END,
    CASE (random() * 3)::INTEGER
        WHEN 0 THEN 'WEBSITE'
        WHEN 1 THEN 'MOBILE_APP'
        ELSE 'LOJA_FISICA'
    END
FROM generate_series(1, 5000000) i;
```
```sql
-- Teste query anal√≠tica
EXPLAIN ANALYZE
SELECT 
    DATE_TRUNC('month', data_venda) as mes,
    regiao_id,
    COUNT(*) as total_vendas,
    SUM(valor_total) as receita,
    AVG(margem_lucro) as margem_media
FROM fato_vendas_ecommerce
WHERE data_venda >= CURRENT_DATE - 365
GROUP BY 1, 2
ORDER BY 1, 2;
-- Este explain vai mostrar Redistribute motion
-- Porque?? --> Group By!
-- Segment 0: Jan/2024 Regi√£o 1 ‚Üí pode ter algumas vendas
-- Segment 1: Jan/2024 Regi√£o 1 ‚Üí pode ter outras vendas
-- Para calcular COUNT(*), SUM(valor_total) corretamente,
-- precisa JUNTAR todas as vendas de (Jan/2024, Regi√£o 1) no mesmo segmento!
```

---

### Exerc√≠cio 2.4.2: Cen√°rio 2 - Sistema Transacional (Pedidos Ativos)

**Contexto:**
- Tabela de pedidos ativos
- UPDATEs frequentes (status, valores)
- Queries buscam pedido completo
- Volume: 50k pedidos ativos simult√¢neos
- Pedidos arquivados ap√≥s conclus√£o

**Qual melhor modelo?**

**Solu√ß√£o Proposta:**
```sql
CREATE TABLE pedidos_ativos (
    pedido_id BIGSERIAL PRIMARY KEY,
    cliente_id INTEGER NOT NULL,
    data_pedido TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    data_atualizacao TIMESTAMP,
    status VARCHAR(30) NOT NULL,
    valor_total NUMERIC(12,2),
    observacoes TEXT,
    vendedor_id INTEGER,
    prioridade SMALLINT,
    CONSTRAINT ck_status CHECK (status IN ('NOVO', 'PROCESSANDO', 'AGUARDANDO_PAGAMENTO', 'PAGO', 'EM_SEPARACAO'))
)
DISTRIBUTED BY (pedido_id);
-- HEAP (padr√£o), ideal para UPDATEs frequentes
```
```sql
-- √çndices para queries comuns
CREATE INDEX idx_pedidos_cliente ON pedidos_ativos(cliente_id);
CREATE INDEX idx_pedidos_status ON pedidos_ativos(status);
CREATE INDEX idx_pedidos_data ON pedidos_ativos(data_pedido);
```
```sql
-- Tabela para itens (1:N)
CREATE TABLE itens_pedido (
    item_id BIGSERIAL,
    pedido_id BIGINT NOT NULL,
    produto_id INTEGER NOT NULL,
    quantidade SMALLINT NOT NULL,
    valor_unitario NUMERIC(10,2) NOT NULL,
    desconto NUMERIC(10,2) DEFAULT 0,
    PRIMARY KEY (pedido_id, item_id)
)
DISTRIBUTED BY (pedido_id);  -- Co-located com pedidos
```

**Justificativas:**
- ‚úÖ **HEAP:** UPDATEs eficientes
- ‚úÖ **Tabela pequena:** 50k linhas, HEAP √© adequado
- ‚úÖ **DISTRIBUTED BY (pedido_id):** Co-location de pedido + itens
- ‚úÖ **√çndices:** Aceleram queries por cliente/status
- ‚ùå **Sem compress√£o:** HEAP n√£o comprime, mas √© pequena


---

### Exerc√≠cio 2.4.3: Cen√°rio 3 - IoT / Telemetria

**Contexto:**
- 1000 sensores enviando dados a cada 10 segundos
- 8.6 milh√µes de leituras/dia
- Queries: agrega√ß√µes por sensor, per√≠odo, tipo
- Sem updates, apenas inser√ß√µes
- Reten√ß√£o detalhada: 90 dias, agregada: 2 anos

**Qual melhor modelo?**

**Solu√ß√£o Proposta:**
```sql
-- Tabela de leituras brutas (detalhada, curto prazo)
CREATE TABLE iot_leituras_raw (
    sensor_id INTEGER,
    timestamp TIMESTAMP,
    tipo_metrica VARCHAR(50),
    valor DOUBLE PRECISION,
    unidade VARCHAR(20),
    qualidade SMALLINT,  -- 0-100
    metadata JSONB
)
WITH (
    appendoptimized=true, --> Porque? Muita opera√ß√£o de Insert apenas.
    orientation=column, --> Porque? Maioria das consultas agregadas AVG, MAX, MIN.
    compresstype=zstd,
    compresslevel=3  -- Baixo: alta taxa inser√ß√£o
)
DISTRIBUTED RANDOMLY  -- Alta taxa inser√ß√£o, distribui√ß√£o uniforme
PARTITION BY RANGE (timestamp)
(
    START (CURRENT_DATE - 90) END (CURRENT_DATE + 1) EVERY (INTERVAL '1 day')
);
```

---

### Exerc√≠cio 2.4.4: Dimens√µes vs Fatos - Coloca√ß√£o

**Objetivo:** Otimizar JOINs com co-location

**Cen√°rio:** Fato de vendas + dimens√µes

**Solu√ß√£o:**
```sql
-- Dimens√£o pequena: REPLICATED
CREATE TABLE dim_produto_replicated (
    produto_id INTEGER PRIMARY KEY,
    nome VARCHAR(200),
    categoria VARCHAR(100),
    marca VARCHAR(100),
    preco_lista NUMERIC(10,2)
)
DISTRIBUTED REPLICATED;
```
```sql
-- Dimens√£o m√©dia: mesma distribui√ß√£o do fato
CREATE TABLE dim_cliente_colocated (
    cliente_id INTEGER PRIMARY KEY,
    nome VARCHAR(200),
    cpf VARCHAR(14),
    data_nascimento DATE,
    cidade VARCHAR(100),
    estado CHAR(2)
)
DISTRIBUTED BY (cliente_id);  -- Mesmo que ser√° usado em fato_vendas
```
```sql
-- Fato distribu√≠do por chave que faz JOIN
CREATE TABLE fato_vendas_otimizado (
    venda_id BIGINT,
    data_venda DATE,
    cliente_id INTEGER,  -- JOIN com dim_cliente_colocated
    produto_id INTEGER,  -- JOIN com dim_produto_replicated
    quantidade INTEGER,
    valor_total NUMERIC(12,2)
)
WITH (appendoptimized=true, orientation=column)
DISTRIBUTED BY (cliente_id);  -- Co-located com dim_cliente!
-- Ou seja, a dim produto ser√° replicada em todos os segmentos, ent√£o o join com ela ser√° local, e a fato foi distribuida pra dar match com a dim cliente.
```

**Popule as tabelas com dados de exemplo:**

```sql
-- 1. Insira dados na dimens√£o produto (REPLICATED)
INSERT INTO dim_produto_replicated
SELECT 
    i,
    'Produto ' || i,
    'Categoria ' || (i % 20),
    'Marca ' || (i % 50),
    (random() * 1000 + 10)::NUMERIC(10,2)
FROM generate_series(1, 500) i;

```

```sql
-- 2. Insira dados na dimens√£o cliente (co-located)
INSERT INTO dim_cliente_colocated
SELECT 
    i,
    'Cliente ' || i,
    LPAD(i::TEXT, 11, '0') || '000',
    CURRENT_DATE - (random() * 36500)::INTEGER,
    'Cidade ' || (i % 100),
    CASE (i % 27)
        WHEN 0 THEN 'SP' WHEN 1 THEN 'RJ' WHEN 2 THEN 'MG' WHEN 3 THEN 'RS'
        WHEN 4 THEN 'PR' WHEN 5 THEN 'SC' WHEN 6 THEN 'BA' WHEN 7 THEN 'PE'
        WHEN 8 THEN 'CE' WHEN 9 THEN 'PA' WHEN 10 THEN 'MA' WHEN 11 THEN 'GO'
        WHEN 12 THEN 'AM' WHEN 13 THEN 'ES' WHEN 14 THEN 'PB' WHEN 15 THEN 'RN'
        WHEN 16 THEN 'AL' WHEN 17 THEN 'MT' WHEN 18 THEN 'PI' WHEN 19 THEN 'DF'
        WHEN 20 THEN 'MS' WHEN 21 THEN 'SE' WHEN 22 THEN 'RO' WHEN 23 THEN 'TO'
        WHEN 24 THEN 'AC' WHEN 25 THEN 'AP' ELSE 'RR'
    END
FROM generate_series(1, 10000) i;

-- Verifique distribui√ß√£o: deve estar balanceada entre segmentos
SELECT 
    gp_segment_id, 
    COUNT(*) as total_clientes,
    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) as percentual
FROM gp_dist_random('dim_cliente_colocated')
GROUP BY gp_segment_id
ORDER BY gp_segment_id;
-- Resultado esperado: Distribui√ß√£o uniforme (~5000 por segmento se 2 segmentos)
```

```sql
-- 3. Insira dados na fato vendas (DISTRIBUTED BY cliente_id)
INSERT INTO fato_vendas_otimizado
SELECT 
    i,
    CURRENT_DATE - (random() * 365)::INTEGER,
    (random() * 9999 + 1)::INTEGER,  -- cliente_id (1-10000)
    (random() * 499 + 1)::INTEGER,   -- produto_id (1-500)
    (random() * 10 + 1)::INTEGER,    -- quantidade
    (random() * 5000 + 100)::NUMERIC(12,2)  -- valor_total
FROM generate_series(1, 1000000) i;

-- Verifique distribui√ß√£o da fato
SELECT 
    gp_segment_id, 
    COUNT(*) as total_vendas,
    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) as percentual
FROM gp_dist_random('fato_vendas_otimizado')
GROUP BY gp_segment_id
ORDER BY gp_segment_id;
-- Resultado esperado: Distribui√ß√£o balanceada (~500k por segmento)
```

**An√°lise de Performance: JOIN por cliente_id (CO-LOCATED) vs produto_id (REPLICATED)**

```sql
-- üéØ TESTE 1: JOIN por cliente_id (CO-LOCATED - SEM MOTION!)
EXPLAIN ANALYZE
SELECT 
    c.estado,
    COUNT(*) as total_vendas,
    SUM(f.valor_total) as receita_total,
    AVG(f.valor_total) as ticket_medio
FROM fato_vendas_otimizado f
INNER JOIN dim_cliente_colocated c ON f.cliente_id = c.cliente_id
WHERE f.data_venda >= CURRENT_DATE - 90
GROUP BY c.estado
ORDER BY receita_total DESC;
-- ‚úÖ RESULTADO ESPERADO:
-- Redistribute DEPOIS do Filtro (Group By)
-- Colocated Join

```
```sql
EXPLAIN ANALYZE
SELECT 
    f.cliente_id,
    COUNT(*) as total_vendas,
    SUM(f.valor_total) as receita_total,
    AVG(f.valor_total) as ticket_medio
FROM fato_vendas_otimizado f
INNER JOIN dim_cliente_colocated c ON f.cliente_id = c.cliente_id
WHERE f.data_venda >= CURRENT_DATE - 90
GROUP BY f.cliente_id
ORDER BY f.cliente_id DESC;
-- ‚úÖ RESULTADO ESPERADO:
-- SEM Redistribute 
-- Colocated Join

```


```sql
-- üîÑ TESTE 2: JOIN por produto_id (REPLICATED - SEM MOTION, mas diferente!)
EXPLAIN ANALYZE
SELECT 
    p.categoria,
    p.marca,
    COUNT(*) as total_vendas,
    SUM(f.valor_total) as receita_total,
    SUM(f.quantidade) as qtd_vendida
FROM fato_vendas_otimizado f
INNER JOIN dim_produto_replicated p ON f.produto_id = p.produto_id
WHERE f.data_venda >= CURRENT_DATE - 90
GROUP BY p.categoria, p.marca
ORDER BY receita_total DESC;

-- ‚úÖ RESULTADO ESPERADO:
-- 1. dim_produto_replicated √© REPLICATED (c√≥pia completa em cada segmento)
-- 2. fato_vendas_otimizado est√° distribu√≠da por cliente_id (n√£o produto_id)
-- 3. MAS como dim_produto est√° replicada, JOIN √© LOCAL!
-- 4. Cada segmento tem TODOS os produtos, ent√£o n√£o precisa buscar em outro segmento
-- 5. Redistribute ocorre em fun√ß√£o do group by, mas √© ap√≥s o filtro.
```


**üìä Compara√ß√£o de Performance:**

```sql
-- Execute todos os testes e compare:
-- (Execute 3x cada e pegue a m√©dia para eliminar varia√ß√£o de cache)

\timing on
```
```sql
-- Teste 1: Co-located JOIN (cliente_id)
SELECT COUNT(*) FROM fato_vendas_otimizado f
INNER JOIN dim_cliente_colocated c ON f.cliente_id = c.cliente_id
WHERE f.data_venda >= CURRENT_DATE - 90;
```
```sql
-- Teste 2: Replicated JOIN (produto_id)
SELECT COUNT(*) FROM fato_vendas_otimizado f
INNER JOIN dim_produto_replicated p ON f.produto_id = p.produto_id
WHERE f.data_venda >= CURRENT_DATE - 90;
```
```sql
\timing off
```

**Resultados Esperados:**

| Teste | Estrat√©gia | Motion? | Tempo M√©dio | Observa√ß√£o |
|-------|-----------|---------|-------------|------------|
| 1 | Co-located (cliente_id) | ‚ùå N√£o | ~250ms | ‚úÖ JOIN totalmente local |
| 2 | Replicated (produto_id) | ‚ùå N√£o | ~230ms | ‚úÖ Dimens√£o replicada em todos segmentos |


**üéØ Li√ß√µes Aprendidas:**

1. **Co-location (mesmo DISTRIBUTED BY):**
   - ‚úÖ Ideal para JOINs frequentes com dimens√µes **grandes/m√©dias**
   - ‚úÖ Zero motion no JOIN
   - ‚úÖ Escal√°vel (distribui o trabalho)
   - ‚ö†Ô∏è S√≥ funciona para 1 chave de distribui√ß√£o por vez

2. **Replica√ß√£o (DISTRIBUTED REPLICATED):**
   - ‚úÖ Ideal para dimens√µes **pequenas** (< 100k linhas, < 50MB)
   - ‚úÖ JOIN com qualquer fato √© local
   - ‚úÖ Flex√≠vel (m√∫ltiplas fatos podem fazer JOIN sem motion)
   - ‚ùå N√£o escala bem (replica em TODOS os segmentos)
   - ‚ùå Aumenta uso de mem√≥ria/disco em cada segmento

**Decis√£o de Design:**

```sql
-- Para schema de data warehouse t√≠pico:

-- Dimens√µes PEQUENAS (< 100k linhas): REPLICATE
CREATE TABLE dim_produto (...) DISTRIBUTED REPLICATED;
CREATE TABLE dim_categoria (...) DISTRIBUTED REPLICATED;
CREATE TABLE dim_tempo (...) DISTRIBUTED REPLICATED;

-- Dimens√µes M√âDIAS/GRANDES: Co-locate com fato principal
CREATE TABLE dim_cliente (...) DISTRIBUTED BY (cliente_id);

-- Fato: Distribua pela FK mais usada em JOINs
CREATE TABLE fato_vendas (
    cliente_id INTEGER,  -- FK mais cr√≠tica
    produto_id INTEGER,  -- OK se dim_produto for REPLICATED
    ...
) DISTRIBUTED BY (cliente_id);  -- Match com dim_cliente

-- Se tiver m√∫ltiplas fatos, pode precisar diferentes distribui√ß√µes:
CREATE TABLE fato_estoque (...) DISTRIBUTED BY (produto_id);
CREATE TABLE fato_vendas (...) DISTRIBUTED BY (cliente_id);
-- Cada fato otimizada para seus JOINs principais
```

---

## Exerc√≠cio Integrador: Redesign de Tabela

**Objetivo:** Aplicar todos os conceitos aprendidos

**Cen√°rio:** Voc√™ recebeu esta tabela mal projetada:

```sql
-- Tabela problem√°tica
CREATE TABLE vendas_problematica (
    id SERIAL,
    data VARCHAR(20),  -- ‚ùå 
    cliente TEXT,
    cpf VARCHAR(14),
    produto TEXT,
    qtd INTEGER,
    preco TEXT,  -- ‚ùå 
    total TEXT,  -- ‚ùå 
    vendedor VARCHAR(100),
    loja VARCHAR(100),
    obs TEXT
)
DISTRIBUTED BY (id);  -- ‚ùå 

```

**Qual melhor modelo?**


**Melhorias poss√≠veis:**
- ‚úÖ Normaliza√ß√£o (dimens√µes separadas)
- ‚úÖ Tipos de dados corretos
- ‚úÖ Storage colunar (AOCO)
- ‚úÖ Compress√£o otimizada por coluna
- ‚úÖ Distribui√ß√£o adequada (venda_id √∫nico)
- ‚úÖ Dimens√µes replicadas (evita motion)
- ‚úÖ Particionamento por data
- ‚úÖ Constraints de integridade

---

## Resumo do M√≥dulo 2

### Habilidades Adquiridas
‚úÖ Escolher estrat√©gia de distribui√ß√£o adequada  
‚úÖ Evitar e corrigir data skew  
‚úÖ Decidir entre row-oriented e column-oriented  
‚úÖ Aplicar compress√£o eficazmente  
‚úÖ Otimizar queries atrav√©s de co-location  
‚úÖ Projetar schemas para data warehouse  
‚úÖ Migrar tabelas mal projetadas  

### Decis√µes Chave de Design

| Aspecto | OLTP / Transacional | OLAP / Anal√≠tico |
|---------|-------------------|------------------|
| **Storage** | HEAP (row) | AOCO (column) |
| **Distribui√ß√£o** | Chave prim√°ria | Chave de JOIN |
| **Compress√£o** | Nenhuma/baixa | M√©dia/alta |
| **Updates** | Frequentes | Raros/nenhum |
| **Particionamento** | Opcional | Recomendado |
| **Dimens√µes** | Normalizadas | Replicadas se pequenas |

### Checklist de Design de Tabela

**Para cada tabela, pergunte:**

1. **Padr√£o de acesso:**
   - [ ] Queries leem linha completa ou poucas colunas?
   - [ ] H√° UPDATEs/DELETEs frequentes?

2. **Distribui√ß√£o:**
   - [ ] Coluna tem alta cardinalidade?
   - [ ] Usada em JOINs frequentes?
   - [ ] Dados est√£o balanceados?

3. **Storage:**
   - [ ] Tabela ser√° grande (> 1GB)?
   - [ ] Dados s√£o append-only?
   - [ ] Queries s√£o anal√≠ticas?

4. **Compress√£o:**
   - [ ] Espa√ßo √© preocupa√ß√£o?
   - [ ] Colunas t√™m padr√µes repetitivos?
   - [ ] Performance de escrita √© cr√≠tica?

### Comandos Principais

```sql
-- Distribui√ß√£o
DISTRIBUTED BY (coluna)
DISTRIBUTED RANDOMLY
DISTRIBUTED REPLICATED

-- Storage
WITH (appendoptimized=true, orientation=row)
WITH (appendoptimized=true, orientation=column)

-- Compress√£o
WITH (compresstype=zstd, compresslevel=5)
ALTER TABLE t ALTER COLUMN c SET ENCODING (compresstype=zlib)

-- Verifica√ß√µes
SELECT * FROM gp_toolkit.gp_skew_coefficients WHERE skcrelname = 'tabela';
SELECT gp_segment_id, COUNT(*) FROM tabela GROUP BY gp_segment_id;
```

### Pr√≥ximos Passos
No **M√≥dulo 3**, voc√™ aprender√° sobre particionamento avan√ßado, √≠ndices e otimiza√ß√£o de queries no Greenplum.

---

**Fim do M√≥dulo 2**
